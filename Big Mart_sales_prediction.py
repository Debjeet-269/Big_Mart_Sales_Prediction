# -*- coding: utf-8 -*-
"""shopping mall sales Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l9cBVn9OlT33ZEsRi3eu0iXQx70CrCAp

Importing the Dependencies
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor
from sklearn import metrics

"""Data Collection and Processing"""

# loading the data from csv file to Pandas DataFrame
big_mart_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Train.csv')

from google.colab import drive
drive.mount('/content/drive')

# first 5 rows of the dataframe
big_mart_data.head()

# number of data points & number of features
big_mart_data.shape

# getting some information about thye dataset
big_mart_data.info()

"""Categorical Features:
- Item_Identifier
- Item_Fat_Content
- Item_Type
- Outlet_Identifier
- Outlet_Size
- Outlet_Location_Type
- Outlet_Type
"""

# checking for missing values
big_mart_data.isnull().sum()

"""Handling Missing Values

Mean --> average

Mode --> more repeated value
"""

# mean value of "Item_Weight" column
big_mart_data['Item_Weight'].mean()

# filling the missing values in "Item_weight column" with "Mean" value
big_mart_data['Item_Weight'].fillna(big_mart_data['Item_Weight'].mean(), inplace=True)

# mode of "Outlet_Size" column
big_mart_data['Outlet_Size'].mode()

# filling the missing values in "Outlet_Size" column with Mode
mode_of_Outlet_size = big_mart_data.pivot_table(values='Outlet_Size', columns='Outlet_Type', aggfunc=(lambda x: x.mode()[0]))

print(mode_of_Outlet_size)

miss_values = big_mart_data['Outlet_Size'].isnull()

print(miss_values)

big_mart_data.loc[miss_values, 'Outlet_Size'] = big_mart_data.loc[miss_values,'Outlet_Type'].apply(lambda x: mode_of_Outlet_size[x])

# checking for missing values
big_mart_data.isnull().sum()

"""Data Analysis"""

big_mart_data.describe()

"""Numerical Features"""

sns.set()

# Item_Weight distribution
plt.figure(figsize=(6,6))
sns.distplot(big_mart_data['Item_Weight'])
plt.show()

# Item Visibility distribution
plt.figure(figsize=(6,6))
sns.distplot(big_mart_data['Item_Visibility'])
plt.show()

# Item MRP distribution
plt.figure(figsize=(6,6))
sns.distplot(big_mart_data['Item_MRP'])
plt.show()

# Item_Outlet_Sales distribution
plt.figure(figsize=(6,6))
sns.distplot(big_mart_data['Item_Outlet_Sales'])
plt.show()

# Outlet_Establishment_Year column
plt.figure(figsize=(6,6))
sns.countplot(x='Outlet_Establishment_Year', data=big_mart_data)
plt.show()

"""Categorical Features"""

# Item_Fat_Content column
plt.figure(figsize=(6,6))
sns.countplot(x='Item_Fat_Content', data=big_mart_data)
plt.show()

# Item_Type column
plt.figure(figsize=(30,6))
sns.countplot(x='Item_Type', data=big_mart_data)
plt.show()

# Outlet_Size column
plt.figure(figsize=(6,6))
sns.countplot(x='Outlet_Size', data=big_mart_data)
plt.show()

"""Data Pre-Processing"""

big_mart_data.head()

big_mart_data['Item_Fat_Content'].value_counts()

big_mart_data.replace({'Item_Fat_Content': {'low fat':'Low Fat','LF':'Low Fat', 'reg':'Regular'}}, inplace=True)

big_mart_data['Item_Fat_Content'].value_counts()

"""Label Encoding"""

encoder = LabelEncoder()

big_mart_data['Item_Identifier'] = encoder.fit_transform(big_mart_data['Item_Identifier'])

big_mart_data['Item_Fat_Content'] = encoder.fit_transform(big_mart_data['Item_Fat_Content'])

big_mart_data['Item_Type'] = encoder.fit_transform(big_mart_data['Item_Type'])

big_mart_data['Outlet_Identifier'] = encoder.fit_transform(big_mart_data['Outlet_Identifier'])

big_mart_data['Outlet_Size'] = encoder.fit_transform(big_mart_data['Outlet_Size'])

big_mart_data['Outlet_Location_Type'] = encoder.fit_transform(big_mart_data['Outlet_Location_Type'])

big_mart_data['Outlet_Type'] = encoder.fit_transform(big_mart_data['Outlet_Type'])

big_mart_data.head()

"""Splitting features and Target"""

X = big_mart_data.drop(columns='Item_Outlet_Sales', axis=1)
Y = big_mart_data['Item_Outlet_Sales']

print(X)

print(Y)

"""Splitting the data into Training data & Testing Data"""

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)

print(X.shape, X_train.shape, X_test.shape)

"""Machine Learning Model Training

XGBoost Regressor
"""

regressor = XGBRegressor()

regressor.fit(X_train, Y_train)

"""Evaluation"""

# prediction on training data
training_data_prediction = regressor.predict(X_train)

# R squared Value
r2_train = metrics.r2_score(Y_train, training_data_prediction)

print('R Squared value = ', r2_train)

# prediction on test data
test_data_prediction = regressor.predict(X_test)

# R squared Value
r2_test = metrics.r2_score(Y_test, test_data_prediction)

print('R Squared value = ', r2_test)

!pip install streamlit --quiet

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor
from sklearn import metrics
import joblib
import pickle

label_encoders = {}
categorical_columns = big_mart_data.select_dtypes(include=['object']).columns
for col in categorical_columns:
    le = LabelEncoder()
    big_mart_data[col] = le.fit_transform(big_mart_data[col])
    label_encoders[col] = le

# Save label encoders for Streamlit app
joblib.dump(label_encoders, 'label_encoders.pkl')

# Save the preprocessed DataFrame for Streamlit app
with open('df.pkl', 'wb') as file:
    pickle.dump(big_mart_data, file)

# Splitting Features and Target

# Features (exclude Item_Outlet_Sales and Item_Identifier)
X = big_mart_data.drop(columns=['Item_Outlet_Sales', 'Item_Identifier'], axis=1)
Y = big_mart_data['Item_Outlet_Sales']

# Split data into training and testing sets
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)

# Model Training: XGBoost Regressor

# Initialize and train the model
regressor = XGBRegressor()
regressor.fit(X_train, Y_train)

# Save the trained model for Streamlit app
with open('big_mart_model.pkl', 'wb') as file:
    pickle.dump(regressor, file)

# Model Evaluation

# Predict on training data
training_data_prediction = regressor.predict(X_train)
r2_train = metrics.r2_score(Y_train, training_data_prediction)
print('R² Score on Training Data:', r2_train)

# Predict on test data
test_data_prediction = regressor.predict(X_test)
r2_test = metrics.r2_score(Y_test, test_data_prediction)
print('R² Score on Test Data:', r2_test)

big_mart_data.info()

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import numpy as np
# import pandas as pd
# import pickle
# import joblib
# 
# # Title and description
# st.title("Big Mart Sales Predictor App")
# st.write("This app predicts sales for Big Mart products based on historical data from the Big Mart Sales dataset.")
# st.write("The predictions are based on the available data and may not perfectly align with real-world sales.")
# 
# # Load the model, label encoders, and DataFrame
# try:
#     model = pickle.load(open('big_mart_model.pkl', 'rb'))
# except FileNotFoundError:
#     st.error("Model file 'big_mart_model.pkl' not found. Please run big_mart_sales_prediction.py first.")
#     st.stop()
# 
# try:
#     label_encoders = joblib.load('label_encoders.pkl')
# except FileNotFoundError:
#     st.error("Label encoders file 'label_encoders.pkl' not found. Please run big_mart_sales_prediction.py first.")
#     st.stop()
# 
# try:
#     df = pickle.load(open('df.pkl', 'rb'))
# except FileNotFoundError:
#     st.error("DataFrame file 'df.pkl' not found. Please run big_mart_sales_prediction.py first.")
#     st.stop()
# 
# # Input widgets for features
# st.header("Enter Product and Outlet Details")
# 
# item_weight = st.slider("Item Weight (in kg)", min_value=4.0, max_value=22.0, step=0.1, value=12.0)
# item_fat_content = st.selectbox("Item Fat Content", df['Item_Fat_Content'].unique(), index=0)
# item_visibility = st.slider("Item Visibility (proportion of display area)", min_value=0.0, max_value=0.33, step=0.01, value=0.05)
# item_type = st.selectbox("Item Type", df['Item_Type'].unique(), index=0)
# item_mrp = st.slider("Item MRP (Maximum Retail Price in ₹)", min_value=30.0, max_value=270.0, step=1.0, value=140.0)
# outlet_identifier = st.selectbox("Outlet Identifier", df['Outlet_Identifier'].unique(), index=0)
# outlet_establishment_year = st.slider("Outlet Establishment Year", min_value=1985, max_value=2009, step=1, value=1999)
# outlet_size = st.radio("Outlet Size", df['Outlet_Size'].unique(), index=1, horizontal=True)
# outlet_location_type = st.selectbox("Outlet Location Type", df['Outlet_Location_Type'].unique(), index=0)
# outlet_type = st.selectbox("Outlet Type", df['Outlet_Type'].unique(), index=0)
# 
# # Prepare input data
# if st.button("PREDICT SALES"):
#     # Create input DataFrame
#     input_data = pd.DataFrame({
#         'Item_Weight': [item_weight],
#         'Item_Fat_Content': [item_fat_content],
#         'Item_Visibility': [item_visibility],
#         'Item_Type': [item_type],
#         'Item_MRP': [item_mrp],
#         'Outlet_Identifier': [outlet_identifier],
#         'Outlet_Establishment_Year': [outlet_establishment_year],
#         'Outlet_Size': [outlet_size],
#         'Outlet_Location_Type': [outlet_location_type],
#         'Outlet_Type': [outlet_type]
#     })
# 
#     # Encode categorical columns
#     categorical_columns = ['Item_Fat_Content', 'Item_Type', 'Outlet_Identifier',
#                           'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type']
#     for column in categorical_columns:
#         if column in label_encoders:
#             try:
#                 input_data[column] = label_encoders[column].transform(input_data[column])
#             except ValueError:
#                 st.error(f"Invalid value for {column}. Please select a valid option.")
#                 st.stop()
#         else:
#             st.error(f"Label encoder for {column} not found.")
#             st.stop()
# 
#     # Predict sales
#     prediction = model.predict(input_data)
#     st.subheader(f"The predicted sales for the item at this outlet is ₹{int(round(prediction[0], -2))}")
# 
# # Display model performance
# st.header("Model Performance")
# st.write("R² Score on Training Data: [Update with actual value from big_mart_sales_prediction.py]")
# st.write("R² Score on Test Data: [Update with actual value from big_mart_sales_prediction.py]")

from sklearn.preprocessing import LabelEncoder
import joblib

label_encoders = {}

for col in ['Item_Fat_Content', 'Item_Type', 'Outlet_Identifier',
            'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type']:
    le = LabelEncoder()
    big_mart_data[col] = le.fit_transform(big_mart_data[col])
    label_encoders[col] = le

# Save the encoders
joblib.dump(label_encoders, 'label_encoders.pkl')

!streamlit run app.py & npx localtunnel --port 8501